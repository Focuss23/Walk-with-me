[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Walk with me",
    "section": "",
    "text": "Descriptive statistics and Graphical Analysis FSt.02\n\n\n\nFood Statistics\n\nAnalysis\n\n\n\n\n\n\n\n\n\nNov 14, 2025\n\n\nLloyd Adu-Kumi\n\n\n\n\n\n\n\n\n\n\n\n\nBBQ production statistics FSt.01\n\n\n\nFood Statistics\n\nAnalysis\n\n\n\n\n\n\n\n\n\nNov 14, 2025\n\n\nLloyd Adu-Kumi\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my journey. A place where I document the things Iâ€™m learning, unlearning, questioning, and exploring. Iâ€™m walking a path shaped by my think pieces, food statistics and epidemiology.\nHere, I dive into:\nStatistics in Food: making sense of data behind what we eat and how itâ€™s produced.\nStatistics in Epidemiology & Health: understanding patterns, risks, and the numbers that influence public health decisions.\nThink Pieces: reflections on life, purpose, growth, and the world around me.\nThis blog is my evolving notebook â€” a place where curiosity leads, insights grow, and new interests join the journey as they come. Weâ€™ll learn, reflect, and discover together.\nSoâ€¦ walk with me."
  },
  {
    "objectID": "posts/Descriptive Analysis/index.html",
    "href": "posts/Descriptive Analysis/index.html",
    "title": "Descriptive statistics and Graphical Analysis FSt.02",
    "section": "",
    "text": "Statistics for Food Scientists\nChapter Commentary:\nMaria is given a tour of the BBQ sauce production plant to understand how manufacturing works (Understanding the food production flow makes the data more relatable!ðŸ˜‰). The plant manager, Lisa, takes her from ingredient handling to mixing, heating, filling, and hourly viscosity checks for quality control. Lisa introduces a new high-speed filling line and asks Maria to produce data to confirm whether the new system truly improves performance.\nTo describe our data, we utilise summary statistics to give an idea of viscosity levels in the individual production line. I love R and Python, but letâ€™s try R for this bookðŸ˜Š!\nLetâ€™s first import our mock data\n\n#load packages\npacman::p_load(\n  rio,  #for importing data\n  here, #for relative file paths\n  skimr, #for reviewing the data\n  lubridate, # for date cleaning\n  janitor, #for cleaning data\n  flextable, #for making pretty tables\n  gtsummary, # creating tables\n  scales, #percents in tables\n  readxl,\n  moments,\n  tidyverse #for data management and viz\n  \n)\n\n#Import Data\nbbq &lt;- import(\"wwm.xlsx\") %&gt;% \n  clean_names() %&gt;%   #to standardize the names of the columns\n  mutate(\n    across(\n      starts_with(\"date\"),\n      ~ mdy_hm(.)\n    )\n  )\nhead(bbq) #Let's return the top 6 rows\n\n      date_and_time_1 line_4_viscosity     date_and_time_3 line_6_viscosity\n1 2013-04-28 08:06:00             4776 2013-04-28 08:05:00             3746\n2 2013-04-28 08:14:00             4318 2013-04-28 08:13:00             4424\n3 2013-04-28 08:23:00             4363 2013-04-28 08:22:00             4284\n4 2013-04-28 08:31:00             4447 2013-04-28 08:30:00             4241\n5 2013-04-28 08:39:00             3832 2013-04-28 08:38:00             4132\n6 2013-04-28 08:48:00             4426 2013-04-28 08:47:00             4189\n\n\nMaybe we could pivot_longer to consolidate the data points\n\nbbq &lt;- bbq %&gt;% \n  pivot_longer(\n    cols = starts_with(\"line\"),\n    names_to = \"line\",\n    values_to = \"viscosity\"\n  ) %&gt;% \n  pivot_longer(\n    cols = starts_with(\"date\"),\n    names_to = NULL,\n    values_to = \"date\"\n  ) \n\nLetâ€™s visualize the data into histograms\n\nggplot(data = bbq,\n       mapping = aes(\n         x = viscosity\n       ))+\n  geom_histogram(bins = 10, fill = \"lightblue\")+\n  labs(\n    y = \"Frequency\"\n  )+\n  facet_wrap(~line)+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nbbq %&gt;% \n  group_by(line) %&gt;% \n  summarise(\n   Mean = mean(viscosity),\n    Median = median(viscosity),\n    `Standard deviation` = sd(viscosity),\n    Kurtosis = kurtosis(viscosity),\n    Skewness = skewness(viscosity),\n    Range = max(viscosity) - min(viscosity),\n    Minimum = min(viscosity),\n    Maximum = max(viscosity)\n  ) %&gt;% \n  qflextable()\n\nlineMeanMedianStandard deviationKurtosisSkewnessRangeMinimumMaximumline_4_viscosity4,293.2874,315318.66062.649792-0.081843581,5503,5355,085line_6_viscosity4,073.0094,120296.21382.301147-0.319931271,2053,4454,650"
  },
  {
    "objectID": "posts/Descriptive Analysis/index.html#descriptive-statistics",
    "href": "posts/Descriptive Analysis/index.html#descriptive-statistics",
    "title": "Descriptive statistics and Graphical Analysis FSt.02",
    "section": "",
    "text": "Statistics for Food Scientists\nChapter Commentary:\nMaria is given a tour of the BBQ sauce production plant to understand how manufacturing works (Understanding the food production flow makes the data more relatable!ðŸ˜‰). The plant manager, Lisa, takes her from ingredient handling to mixing, heating, filling, and hourly viscosity checks for quality control. Lisa introduces a new high-speed filling line and asks Maria to produce data to confirm whether the new system truly improves performance.\nTo describe our data, we utilise summary statistics to give an idea of viscosity levels in the individual production line. I love R and Python, but letâ€™s try R for this bookðŸ˜Š!\nLetâ€™s first import our mock data\n\n#load packages\npacman::p_load(\n  rio,  #for importing data\n  here, #for relative file paths\n  skimr, #for reviewing the data\n  lubridate, # for date cleaning\n  janitor, #for cleaning data\n  flextable, #for making pretty tables\n  gtsummary, # creating tables\n  scales, #percents in tables\n  readxl,\n  moments,\n  tidyverse #for data management and viz\n  \n)\n\n#Import Data\nbbq &lt;- import(\"wwm.xlsx\") %&gt;% \n  clean_names() %&gt;%   #to standardize the names of the columns\n  mutate(\n    across(\n      starts_with(\"date\"),\n      ~ mdy_hm(.)\n    )\n  )\nhead(bbq) #Let's return the top 6 rows\n\n      date_and_time_1 line_4_viscosity     date_and_time_3 line_6_viscosity\n1 2013-04-28 08:06:00             4776 2013-04-28 08:05:00             3746\n2 2013-04-28 08:14:00             4318 2013-04-28 08:13:00             4424\n3 2013-04-28 08:23:00             4363 2013-04-28 08:22:00             4284\n4 2013-04-28 08:31:00             4447 2013-04-28 08:30:00             4241\n5 2013-04-28 08:39:00             3832 2013-04-28 08:38:00             4132\n6 2013-04-28 08:48:00             4426 2013-04-28 08:47:00             4189\n\n\nMaybe we could pivot_longer to consolidate the data points\n\nbbq &lt;- bbq %&gt;% \n  pivot_longer(\n    cols = starts_with(\"line\"),\n    names_to = \"line\",\n    values_to = \"viscosity\"\n  ) %&gt;% \n  pivot_longer(\n    cols = starts_with(\"date\"),\n    names_to = NULL,\n    values_to = \"date\"\n  ) \n\nLetâ€™s visualize the data into histograms\n\nggplot(data = bbq,\n       mapping = aes(\n         x = viscosity\n       ))+\n  geom_histogram(bins = 10, fill = \"lightblue\")+\n  labs(\n    y = \"Frequency\"\n  )+\n  facet_wrap(~line)+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nbbq %&gt;% \n  group_by(line) %&gt;% \n  summarise(\n   Mean = mean(viscosity),\n    Median = median(viscosity),\n    `Standard deviation` = sd(viscosity),\n    Kurtosis = kurtosis(viscosity),\n    Skewness = skewness(viscosity),\n    Range = max(viscosity) - min(viscosity),\n    Minimum = min(viscosity),\n    Maximum = max(viscosity)\n  ) %&gt;% \n  qflextable()\n\nlineMeanMedianStandard deviationKurtosisSkewnessRangeMinimumMaximumline_4_viscosity4,293.2874,315318.66062.649792-0.081843581,5503,5355,085line_6_viscosity4,073.0094,120296.21382.301147-0.319931271,2053,4454,650"
  }
]